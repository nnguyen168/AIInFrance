# 什么是梯度
梯度的本意是一个向量，表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大
- [梯度](https://baike.baidu.com/item/%E6%A2%AF%E5%BA%A6/13014729)

# 梯度和残差的关系

# 什么是梯度下降
1. 梯度下降法是一个一阶最优化算法，要使用梯度下降法找到一个函数的局部极小值，必须向函数上当前点对应梯度（或者是近似梯度）的反方向的规定步长距离点进行迭代搜索。如果相反地向梯度正方向迭代进行搜索，则会接近函数的局部极大值点；这个过程则被称为梯度上升法
2. 为了让损失函数的数值下降，那么就需要使用优化算法进行优化，其中，损失函数值下降最快的方向称为负梯度方向，所使用的算法称为梯度下降法

# 什么是梯度消失

# 怎么解决梯度消失

# Batchnorm的原理和作用

# Bagging和Dropout有什么区别
1. 目的都是为了防止过拟合，但是bagging是针对于data，dropout是针对于特征
2. Bagging的各个模型之间是相互独立的，而Dropout各个模型之间是共享权重的
3. Bagging是随机抽样，训练多个模型投票。Dropout相当于特征选择
- [神经网络中的Dropout和Bagging](http://sofasofa.io/forum_main_post.php?postid=1000436)
- [Dropout的Bagging思想以及使用要点](https://zhuanlan.zhihu.com/p/163833907)

# Bert最后一层输出的词向量是什么意思
